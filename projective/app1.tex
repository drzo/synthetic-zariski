\section*{Appendix 1: Horrock's Theorem}

We present a constructive proof of the the following special case of the {\em affine}
Horrocks Theorem \cite{Lam}, V.2, for a commutative ring $A$. We
essentially follow Nashier-Nichols' Proof of Horrocks Theorem, as presented in \cite{Lam}, IV.5.
(Another constructive proof can be found in \cite{lombardi-quitte}, XVI.4).

\begin{lemma}\label{Horrocks}
  If an ideal of $A[X]$ divides a principal ideal $(f)$ with $f$ monic then it is itself a principal ideal.
\end{lemma}

Let $L$ and $M$ be such that $L\cdot M = (f)$. We can then write $f = \Sigma u_iv_i$ with $u_i$ in $L$ and
$v_i$ in $M$. Using $f$ monic, we then have $L = (u_1,\dots,u_n)$ and $M = (v_1,\dots,v_n)$.
The strategy of the proof is to build comaximal monoids $S_1,\dots,S_l$ in $A$ \cite{lombardi-quitte},
XIV.1, such that $L$ is generated by a monic polynomial in each $A_{S_j}[X]$.

\subsection{Formal computation of gcd}

%We start by describing a general technique introduced in \cite{lombardi-quitte}.

 If we have a list $u_1,\dots,u_n$ of polynomials over a field we can compute the gcd of this list
$(g) = (u_1,\dots,u_n)$ and $g$ is either $0$ (in the case where all the polynomials $u_1,\dots,u_n$ are $0$)
 or a monic polynomial. More generally, over a local ring $A$ which is residually discrete of maximal
 ideal $m$, we can compute a polynomial $g$ in $A[X]$ such that 
 $(g) = (u_1,\dots,u_n)$ modulo $m$
 and $g$ is either $0$ (in the case where all the polynomials $u_1,\dots,u_n$ are $0$ modulo $m$)
 or a monic polynomial.

In general, if we are over an arbitrary ring $A$, we can interpret this computation formally as
follows (\cite{lombardi-quitte}, XIV.1). We build a binary tree of root $A$, where at each node,
we intuitively force an element of $A$ to be in the Jacobson radical
or to be invertible modulo this ideal.
To each node is associated a pair of finite sets $I;U$
of elements in $A$ and we associate the monoid $S(I;U) = M(U) + (I)$ where $M(U)$ is the multiplicative
monoid generated by $U$ and $(I)$ the ideal generated by $I$.

Corresponding to the formal computation of the gcd, we get a binary tree where we have at each leaf
a ring $A_{S(I;U)}$ and a polynomial $g$ in $A_{S(I;U)}[X]$, which is monic or $0$, and
such that $(g) = (u_1,\dots,u_n)$ modulo the ideal generated by $I$ in $A_{S(I;U)}$.

%% We have assumed that the ideal $(u_1,\dots,u_n)$ in $A[X]$
%% contains a monic polynomial, so we can only have $g = 0$ if $1=0$ in $A(I;U)$ and we can replace
%% $g$ by $1$. So in the case where the ideal $(u_1,\dots,u_n)$ in $A[X]$ contains a monic
%% polynomial, we can assume that on each leach we have a {\em monic} polynomial.

%% Like in \cite{lombardi-quitte}, XIV.1, we can also associate to each branch
%% the multiplicative monoid $S(I;U) = M(U) + (I)$.
%% In the ring $A_{S(I;U)}$ we force the elements in $U$ to be invertible {\em and} the elements
%% in $I$ to be in the Jacobson radical \cite{lombardi-quitte}.
If we do this for each branch, we get a list of monoids $S_1,\dots,S_l$
that are {\em comaximal} (\cite{lombardi-quitte}, XIV.1): if $s_i$ in $S_i$ then $1 = (s_1,\dots,s_l)$.

\subsection{Application to Horrocks' Theorem}

We assume that $(u_1,\dots,u_n)$ divides $(f)$, with $f$ monic.
The goal is to build comaximal monoids $S_1,\dots,S_l$ with $(u_1,\dots,u_n)$ principal
and generated by a monic polynomial in $A_{S_j}[X]$.

Note that $(u_1,\dots,u_n)$ contains the monic polynomial $f$.

We first build a binary tree which corresponds to the formal computation of the gcd of
$u_1,\dots,u_n$ as described above. For each branch $I;U$ we have a monic polynomial
$g$ in $A_{S(I;U)}[X]$, which belongs to $(u_1,\dots,u_n)$, and
such that $(u_1,\dots,u_n) = (g)$ modulo\footnote{Since $(u_1,\dots,u_n)$
contains a monic polynomial, the case where $g=0$ can only happen if $0$ belongs to in $S(I;U)$ and in this
case, we can replace $g$ by $1$.} the ideal generated by $I$.

The next Lemma is Lemma IV.5.1, \cite{Lam} in Lam's presentation of
Nashier-Nichols' Proof of Horrocks Theorem.

\begin{lemma}
  Let $R$ be a ring with an ideal $J$ contained in the Jacobson radical
  and $L$ an ideal of $R[X]$ which contains a monic polynomial. We consider
  the reduction modulo $J$
  $$\pi: R[X]\mapsto (R/J)[X]$$
  Any monic polynomial of $\pi(L)$ can be lifted to a monic polynomial in $L$.
\end{lemma}

 Using this Lemma, we get a monic polynomial $h$ in $(u_1,\dots,u_n)$ in $A_{S(I;U)}[X]$
 and such that $h$ generates $(u_1,\dots,u_n)$ modulo $(I)$.
 We can now use that $I$ is contained in the Jacobson radical of $A_{S(I;U)}$ and the
 following second Lemma, which corresponds to Proposition IV.5.2 of \cite{Lam},
 to conclude that we actually have $(h) = (u_1,\dots,u_n)$ in $A_{S(I;U)}[X]$.

\begin{lemma}
  Let $R$ a ring, $J$ an ideal of $R$ contained in the Jacobson radical of $R$. If
  we have $L\cdot M = (f)$ with $f$ monic in $R[X]$, and $L$ contains a monic polynomial
  $h$ such that $L = (h)$ in $(R/J)[X]$ then $L = (h)$ in $R[X]$.
\end{lemma}

\begin{proof}
  Since $L$ contains $L\cap J$ and $L\cdot M = (f)$ with $f$ regular (since $f$ is monic),
  we can find $K$   such that $L\cdot K = L\cap J$. Indeed, we have $(L\cap J)\cdot M \subseteq (f)$
  and so we can write $f K = (L\cap J)\cdot M$. We then have $f (L\cdot K) = (L\cap J)\cdot L\cdot M = f (L\cap J)$
  and so $L\cdot K = L\cap J$ since $f$ is monic.
  We then have $L\cdot K = 0$ modulo $J$ and hence $K = 0$ modulo $J$ since $L$ contains $f$
  which is monic.
  This means $L\cap J = L\cdot J$. Then we have $L = (h) + L\cdot J$.
  The result then follows from the fact that $h$ is monic and from Nakayama's Lemma, as in Lam \cite{Lam}:
  the module $P = L/(h)$ is a finitely generated module over $R$, since $f$ is monic, and satisfies
  $P\subseteq JP$ and $J$ is contained in the Jacobson radical of $R$, so $P = 0$ by Nakayama's Lemma.
\end{proof}

\begin{corollary}
  We can find comaximal elements $s_1,\dots,s_l$ such that $(u_1,\dots,u_n)$ is principal and generated by a
  monic polynomial in each $A_{s_j}[X]$. Since these monic polynomials are uniquely determined
  we can patch these generators and get that $(u_1,\dots,u_n)$ is principal in $A[X]$\footnote{If $A$ is not
  connected, the generator of $(u_1,\dots,u_n)$ may not be monic: if $e(1-e)=1$ then the ideal $(eX+(1-e))$
  divides the ideal $(X)$.}.
\end{corollary}

\newpage

\section*{Appendix 2: proof of Proposition \ref{units}}

\begin{proof}
%  (We follow essentially David's argument.)
  Each $u_{ij}$ is such that $u_{ij}(p)$ unit for $p=0$ and
  all $u_{ij}(p)$ nilpotent for $p\neq 0$.

  Like in the proof of \Cref{nilpotent}, we can change $u_{01}$ so that
  we have $u_{01}(p) = 0$ if $p\neq 0$ and $p_0\geqslant 0$ or $p_1\geqslant 0$ by multiplying $u_{01}$ by a unit in $T_0$ and
  a unit in $T_1$. Let us show for instance how to force $u_{01}(p) = 0$ if $p\neq 0$ and $p_1\geqslant 0$ by multiplying $u_{01}$
  by a unit in $T_0$. Let $M$ be the ideal generated by $u_{01}(p)$ for $p\neq 0$, which is a nilpotent ideal. If we
  multiply $u_{01}$ by $u_{01}(0) - \Sigma_{p_1\geqslant 0,p\neq 0} u_{01}(p)$
  we change $u_{01}$ to $u'_{01}$ where all $u_{01}'(p)$, for $p_1\geqslant 0$ and $p\neq 0$, are in $M^2$. We iterate this process
  and since $M$ is nilpotent, we force $u_{01}(p) = 0$ or $p\neq 0$ and $p_1\geqslant 0$.

  We can thus assume that $u_{01}(p) = 0$ if $p\neq 0$ and $p_0\geqslant 0$ or $p_1\geqslant 0$.
  
  We claim then that, in this case, $u_{01}$ has to be a unit. For this we show that $u_{01}(p) = 0$
  if $p_l>0$ for each $l\neq 0,1$. 
  This is obtained by looking at the relation $u_{01}= u_{0l}u_{l1}$, that is
  $$u_{01}(p) = u_{0l}(p)u_{l1}(0) + u_{0l}(0)u_{l1}(p) + \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)\leqno{(1)}$$
  which can be written as
  $$u_{0l}(p)u_{l1}(0) = - u_{01}(p) + u_{0l}(0)u_{l1}(p) + \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)\leqno{(2)}$$
  (recall that $u_{l1}(0)$ is a unit).

  Let $L$ be the ideal generated by
  coefficients $u_{0l}(p)$ and $u_{l1}(p)$ with $p_l>0$ and $I$
  the ideal generated by all nilpotent coefficients of $u_{0l}$ and $u_{l1}$. We show that $L=0$.

  Thanks to the form of $u_{01}$ we will show that $L\subseteq LI$ and so $L=0$ by Nakayama.
  For this we use $(2)$ and show that $u_{0l}(p)$ is in $LI$. 

  Since $p_l>0$, we have $u_{0l}(p) = 0$ if $p_0\geqslant 0$ since $\Sigma p = 0$ and $u_{0l}$ is in $T_{0l}$. So we can assume $p_0<0$.
  
  We also have $u_{0l}(p) = 0$ if $p_1<0$ since $u_{0l}$ is in $T_{0l}$ and we can assume $p_1\geqslant 0$ as well.
  
  This implies $u_{l1}(p) = 0$ (since $p_0<0$ and $u_{l1}$ in $T_{l1}$)
  and $u_{01}(p) = 0$ (since $p\neq 0$ and $0\leqslant p_1$).
  
  We get thus
  $$u_{0l}(p)u_{l1}(0) = - \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)$$
  and each member in the sum $u_{0l}(q)u_{l1}(r)$ is in $IL$ since $q_l+r_l = p_l>0$ and hence $q_l>0$ or $r_l>0$.

  Similarly, using
  $$u_{0l}(0)u_{l1}(p) = - u_{01}(p) + u_{0l}(p)u_{l1}(0) + \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)$$
  we show that $u_{l1}(p)$ is in $IL$. So we have $L\subseteq LI$.

  We thus deduce $L=0$ by Nakayama.

  The equality $(1)$ becomes, for $p_l>0$
  $$u_{01}(p) = u_{0l}(p)u_{l1}(0) + u_{0l}(0)u_{l1}(p)$$
  and if $p_0<0$ and $p_1<0$ we have $u_{0l}(p) = u_{l1}(p) = 0$.

  This implies that all coefficients $u_{01}(p)$ such that $p_l>0$ are $0$.

  Since this holds for each $l>1$ we have that $u_{01}$ is a unit in $R$.

  W.l.o.g. we can assume $u_{01}= 1$. We then have $u_{0l} = u_{01}u_{1l} = u_{1l}$ in $T_{0l}\cap T_{1l} = T_l$
  and we take $s_l = u_{0l} = u_{1l}$.
\end{proof}

\newpage


\section*{Appendix 3: Quillen Patching}

We reproduce the argument in Quillen's paper \cite{Quillen}, as simplified in \cite{lombardi-quitte}.
This technique of Quillen Patching has been replaced by the equivalence in Proposition \ref{Matthias}.

Let $P(X)$ be a presentation matrix of a finitely presented module $M$ over a ring $A[X]$. We say that $M$
is extended from $A$ if the matrix $P(X)$ and the matrix $P(0)$ presents isomorphic modules \cite{lombardi-quitte}, Ch. XVI.

 Quillen Patching can be presented as the following result.

\begin{theorem}\label{QP}
  If we have $M$ finitely presented of $A[X]$ and $f_1,\dots,f_n$ comaximal elements of $A$
  such that each $M\otimes_{A[X]} A[1/f_i][X]$ is extended from $A[1/f_i]$ then $M$ is extended from $A$.
\end{theorem}

Let us reformulate this result in the setting of Synthetic Algebraic Geometry \cite{draft}.
If $A$ is a finitely presented $R$-algebra, we know \cite{draft}, Theorem 7.2.3, that there is an
equivalence between $\fpMod{A[X]}$ and ${\fpMod{R}}^{\Spec(A)\times R}$, which to a module $M$
associates the family $M\otimes_{A[X]} (x,r)$ for $x:\Spec(A)$ and $r:R$. Conversely, to a family $L~x~r$
of finitely presented $R$-modules, we associate the finitely presented $A[X]$-module $\prod_{x:\Spec(A)}\prod_{r:R}L~x~r$.
We deduce from this the following characterisation of extended modules from $A$.

\begin{proposition}
  the module corresponding to the
family $L~x~r$ is extended from $A$ if, and only if, we have $\prod_{x:\Spec(A)}\prod_{r:R}L~x~r = L~x~0$.
\end{proposition}

We can then reformulate Theorem \ref{QP} as follows.

\begin{corollary}
  If we have $f_1,\dots,f_n$ comaximal elements of $A$ and $\prod_{x:D(f_i)}\prod_{r:R}L~x~r = L~x~0$ for $i=1,\dots, n$
  then $\prod_{x:\Spec(A)}{\prod_{x:R}L~x~r = L~x~0}$.
\end{corollary}

It follows then from local choice that we have.

\begin{corollary}\label{QP1}
  If $\prod_{x:\Spec(A)}{\|{\prod_{r:R}{L~x~r = L~x~0}}\|}$ then 
  $\|{\prod_{x:\Spec(A)}{\prod_{x:R}{L~x~r = L~x~0}}}\|$.
\end{corollary}

We can now compare Quillen's argument which uses Corollary \ref{Pic1} and Theorem \ref{QP}
instead of its refinement Corollary \ref{Matthias1}.

\begin{proposition}%\label{trivial}
  For all $V:\bP^n\rightarrow \KR$ we have $\|{\prod_{s:R^n}V([1:s]) = V([0:1:0:\cdots :0])}\|$.
\end{proposition}

\begin{proof}
  We define $L:R^{n-1}\rightarrow (\bP^1 \to \KR)$ by $L~t~[x_0:x_1] = V([x_0:x_1:x_0t])$.
  Let $s=(s_1,\dots,s_{n}):R^{n}$. We apply Corollary \ref{Pic1} and we get, for all $s_2,\dots,s_n$
  \[
   \|{V([1:s]) = L~(s_2,\dots,s_n)~[1:s_1] = L~(s_2,\dots,s_n)~[0:1]}\|
   \rlap{.}
   \]
   Using Corollary \ref{QP1}, we get $\|{\prod_{s:R^n}V([1:s]) = V([0:1:0:\cdots :0])}\|$.
\end{proof}




\newpage

\section*{Appendix 4: Classical argument}

We reproduce a message of Brian Conrad in MathOverflow \cite{conrad-mathoverflow-16324}.

\medskip

``We know that the Picard group of projective $(n-1)$-space over a field $k$ is $\Z$
generated by $\OO(1)$.
This underlies the proof that the automorphism group of such a projective space is $\PGL_n(k)$.
But what is the automorphism group of $\bP^{n-1}(A)$ for a general ring $A$? Is it $\PGL_n(A)$?
It's a really important fact that the answer is yes.
But how to prove it? It's a shame that this isn't done in Hartshorne.

By an elementary localization, we may assume $A$ is local.
In this case we claim that $\Pic(\bP^{n-1}(A))$ is infinite cyclic generated by $\OO(1)$.
Since this line bundle has the known $A$-module of global sections,
it would give the desired result if true by the same argument as in the field case.
And since we know the Picard group over the residue field, we can twist
to get to the case when the line bundle is trivial on the special fiber. How to do it?

\medskip

 Step 0: The case when $A$ is a field. Done.

 \medskip

 Step 1: The case when $A$ is Artin local.
 This goes via induction on the length, the case of length $0$ being Step $0$
 and the induction resting on cohomological results for projective space over the residue field.

  \medskip

 Step 2: The case when $A$ is complete local noetherian ring. This goes
 using Step 1 and the theorem on formal functions (formal schemes in disguise).

  \medskip

 Step 3: The case when $A$ is local noetherian.
 This is faithfully flat descent from Step 2 applied over $A~\widehat{}$

 \medskip
 
 Step 4: The case when $A$ is local:
 descent from the noetherian local case in Step 3 via direct limit arguments.

\medskip
 
QED''
