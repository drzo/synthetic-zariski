
\subsection{Construction of projective spaces}
We give two definitions of projective space, which differ only in size.
First, we will define $n$-dimensional projective space,
as the type of lines in a $(n+1)$-dimensional vector space $V$.
This gives a good mapping-in property --
maps from a type $X$ into projective space are then just families of lines in $V$ on $X$.
Or in the words of traditional algebraic geometry:
projective $n$-space is a fine moduli space for lines in $V$.

The second construction is closer to what can be found in a typical
introductory textbook on algebraic geometry
(see for example \cite[Section I.2]{Hartshorne}),
i.e.\ projective $n$-space is constructed as a quotient of $\A^{n+1}\setminus\{0\}$.
We will show that this quotient is a scheme,
again analogous to what can be found in textbooks.
In both, construction and proof,
we do not have to pass to an algebraic representation
and can work directly with the types of interest.
Finally, in \cref{space-of-lines-is-projective-space}
we show that the two constructions are equivalent.

\begin{definition}%
  \begin{enumerate}[(a)]
  \item An $n$-dimensional $R$-\notion{vector space} is an $R$-module $V$,
    such that $\propTrunc{ V = R^n }$. 
  \item We write $\Vect{R}{n}$ for the type of these vector spaces and $V\setminus\{0\}$ for the type
    \[ \sum_{x:V}x\neq 0\]
  \item A \notion{vector bundle} on a type $X$ is a map $V:X\to \Vect{R}{n}$. 
  \end{enumerate}
\end{definition}

The following defines projective space as the space of lines in a vector space.
This is a large type.
We will see below, that there is also a small definition of the same type.

\begin{definition}%
  \label{projective-space-as-space-of-lines}
  \begin{enumerate}[(a)]
  \item A \notion{line} in a $R$-vector space $V$ is a subtype $L:V\to \Prop$,
    such that there exists an $x:V\setminus\{0\}$ with
    \[ \prod_{y:V}\left(L (y) \Leftrightarrow \exists c:R.y=c\cdot x\right)\]
  \item The space of all lines in a fixed $n$-dimensional vector space $V$ is the \notion{projectivization} of $V$:
    \[ \bP(V)\colonequiv \sum_{L:V\to \Prop} L \text{ is a line}  \]
  \item \notion{Projective $n$-space} $\bP^n \colonequiv \bP(\A^{n+1})$ is the projectivization of $\A^{n+1}$.
  \end{enumerate}
\end{definition}

\begin{proposition}%
  \label{lines-are-one-dimensional}
  For any vector space $V$ and line $L\subseteq V$,
  $L$ is 1-dimensional in the sense that $\propTrunc{L=_{\Mod{R}}R}$.
\end{proposition}

\begin{proof}
  Let $L$ be a line.
  We merely have $x:V\setminus\{0\}$ such that 
  \[ \prod_{y:V}\left(L (y) \Leftrightarrow \exists c:R.y=c\cdot x\right)\]
  We may replace the ``$\exists$'' with a ``$\sum$'',
  since $c$ is uniquely determined for any $x,y$.
  This means we can construct the map $\alpha\mapsto \alpha\cdot x:R\to L$ and it is an equivalence.
\end{proof}

We now give the small construction:

\begin{definition}[using \axiomref{loc}, \axiomref{sqc}]%
  \label{projective-space-hit}
  Let $n:\N$.
  \notion{Projective $n$-space}\index{$\bP^n$} $\bP^n$ is the setquotient of the type $\A^{n+1}\setminus\{0\}$ by the relation
  \[
    x \sim y \colonequiv \sum_{\lambda : R} \lambda x=y\rlap{.}
  \]
  By \cref{generalized-field-property}, the non-zero vector $y$ has an invertible entry,
  so that the right hand side is a proposition and $\lambda$ is a unit.
  We write $[x_0:\dots:x_n]:\bP^n$ for the equivalence class of $(x_0,\dots,x_n):\A^{n+1}\setminus\{0\}$.
\end{definition}

\begin{theorem}[using \axiomref{sqc}, \axiomref{loc}]%
  \label{projective-space-is-scheme}
  $\bP^n$ is a scheme.
\end{theorem}

\begin{proof}
  Let $U_i([x_0:\dots:x_n])\colonequiv (x_i\neq 0)$.
  This is well-defined, since the proposition is invariant under multiplication by a unit.
  Furthermore, $U_i$ is open and the $U_i$ form a cover,
  by the generalized field property
  (\cref{generalized-field-property}).

  So what remains to be shown, is that the $U_i$ are affine.
  We will show that $U_i=\A^n$.
  As an intermediate step, we have:
  \[
    U_i=\{(x_0,\dots,x_n):\A^{n+1}\mid x_i=1\}
  \]
  by mapping $[x_0:\dots:x_n]$ with $x_i\neq 0$
  to $\left(\frac{x_0}{x_i},\dots,\frac{x_n}{x_i}\right)$
  and conversely, $(x_0,\dots,x_n)$ with $x_i=1$ to $[x_0:\dots:x_{i-1}:1:x_{i+1}:\dots:x_n]\in U_i$.

  But then, $\{(x_0,\dots,x_n):\A^{n+1}\mid x_i=1\}$
  is equivalent to $\A^n$ by leaving out the $i$-th component,
  so the $U_i$ are affine.
\end{proof}

To conclude with the constructions of projective space,
we show that our two constructions are equivalent:

\begin{proposition}[using \axiomref{sqc}, \axiomref{loc}]
  \label{space-of-lines-is-projective-space}
  For all $n:\N$, the scheme $\bP^n$ as defined in \cref{projective-space-hit},
  is equivalent to $\bP(\A^{n+1})$ as defined in \cref{projective-space-as-space-of-lines}.
\end{proposition}

\begin{proof}
  Let $\varphi:\bP^n\to \{\text{lines in $\A^{n+1}$}\}$
  be given by mapping $[x_0:\dots:x_n]$ to $\langle (x_0,\dots,x_n)\rangle\subseteq \A^{n+1}$,
  i.e.\ the line generated by the vector $x\colonequiv (x_0,\dots,x_n)$.
  The map is well-defined, since multiples of $x$ generate the same line.

  Then $\varphi$ is surjective,
  since for any line $L\subseteq \A^{n+1}$,
  there merely is a non-zero $x\in L$,
  that we can take as a preimage.
  To conclude, we note that $\varphi$ is also an embedding.
  So let $\varphi([x])=\varphi([y])$.
  Then, since $\langle x\rangle=\langle y\rangle$, there is a $\lambda\in R^\times$,
  such that $x=\lambda y$, so $[x]=[y]$.
\end{proof}

\subsection{Functions on $\bP^n$}

We start with some preliminaries on equality of points in $\bP^n$,
before we work towards the classical fact, that all functions $\bP^n\to R$ are constant.

\begin{lemma}[using \axiomref{sqc}, \axiomref{loc}]
  \label{equality-2-by-2-minor}
  For two points $[x_0:\dots:x_n],[y_0:\dots:y_n]:\bP^n$ we have:
  \[
    [x]=[y] \Leftrightarrow \prod_{i\neq j}x_iy_j=y_ix_j
    \rlap{.}
  \]
  And dually:
  \[
    [x]\neq [y] \Leftrightarrow \bigvee_{i\neq j}x_iy_j\neq y_ix_j
    \rlap{.}
  \]
  As a consequence, $[x]=[y]$ is closed and $[x]\neq [y]$ is open.
\end{lemma}

\begin{proof}
  $[x]$ and $[y]$ are equal,
  if and only if there merely is a $\lambda:R^\times$,
  such that $\lambda x = y$.
  By calculation, if there is such a $\lambda$,
  we always have $x_iy_j=y_ix_j$.

  So let $x_iy_j=y_ix_j$ for all $i\neq j$.
  Then, in particular, there are $i,j$ such that $x_i\neq 0$ and $y_j\neq 0$.
  If $i=j$, we define $\lambda \colonequiv \frac{x_i}{y_i}$.
  If $i\neq j$, we have $x_iy_j=y_ix_j$ and therefore $y_i\neq 0$ and $x_j\neq 0$,
  so we can also set $\lambda \colonequiv \frac{x_i}{y_i}$.
  By calculation, we have $\lambda y=x$.

  The dual statement follows by \cref{generalized-field-property}.
\end{proof}

\begin{lemma}[using \axiomref{sqc}, \axiomref{loc}]%
  \label{projective-space-apartness-relation}
  Inequality of points of $\bP^n$ is an \notion{apartness relation}.
  That means the following holds:
  \begin{enumerate}[(i)]
  \item $\forall x:\bP^n.\; x\neq x$.
  \item $\forall x,y:\bP^n.\; x\neq y\Rightarrow y\neq x$.
  \item If $x\neq y$, we have $\forall z:\bP^n.\; x\neq z \vee z\neq y$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  The first two statements hold in general for inequality.
  For the third statement, let $x,y,z:\bP^n$.
  Note that if $x=z$ and $z=y$, it follows that $x=y$.
  So we have $\neg (x=y)\Rightarrow \neg (x=z\wedge z=y)$.
  By \cref{equality-2-by-2-minor}, $x=y$ and $x=z\wedge z=y$
  are both equivalent to the statement that some vector with components in $R$ is zero,
  so we can replace negated equality, with existence of a non-zero element,
  or more explicitly, the following are equivalent:
  \begin{align*}
    &\neg (x=y)\Rightarrow \neg (x=z\wedge z=y) \\
    &\neg \left(\prod_{i\neq j}x_iy_j=y_ix_j\right)
       \Rightarrow \neg \left(\prod_{i\neq j}x_iz_j=z_ix_j \wedge \prod_{i\neq j}y_iz_j=z_iy_j \right) \\
    & \left(\bigvee_{i\neq j}x_iy_j\neq y_ix_j\right) \Rightarrow \left(\bigvee_{i\neq j}x_iz_j\neq z_ix_j
       \vee \bigvee_{i\neq j}z_iy_j\neq y_iz_j\right) \\
    & (x\neq y) \Rightarrow (x\neq z) \vee (z\neq y)
  \end{align*}
\end{proof}

\begin{example}[using \axiomref{loc}]
  Let $s:\bP^1\to \bP^1$ be given by $s([x:y])\colonequiv [x^2:y^2]$
  (see \cref{projective-space-hit} for notation).
  Let us compute some fibers of $s$. The fiber $\fib_s([0:1])$ is
  by definition the type
  \[
    \sum_{[x:y]:\bP^1}[x^2:y^2]=[0:1]\rlap{.}
  \]
  So for any $x:R$ with $x^2=0$, $[x:1]:\fib_s([0:1])$  and
  any other point $(x,y)$ such that $[x:y]$ is in $\fib_s([0:1])$,
  already yields an equivalent point, since $y$ has to be invertible.

  This shows that the fiber over $[0:1]$ is a first order disk, i.e. $\D(1)=\{x:R|x^2=0\}$.
  The same applies to the point $[1:0]$.
  To analyze $\fib_s([1:1])$, let us assume $2\neq 0$ (in $R$).
  Then we know, the two points $[1:-1]$ and $[1:1]$ are in $\fib_s([1:1])$ and they are different.
  It will turn out, that any point in $\fib_s([1:1])$ is equal to one of those two.
  For any $[x':y']:\fib_s([1:1])$, we can assume $[x':y']=[x:1]$ and $x^2=1$, or equivalently $(x-1)(x+1)=0$.
  By \cref{projective-space-apartness-relation}, inequality in $\bP^n$ is an apartness relation.
  So for each $x:R$, we know $x-1$ is invertible or $x+1$ is invertible.
  But this means that for any $x:R$ with $(x-1)(x+1)=0$, that $x=1$ or $x=-1$.

  While the fibers are not the same in general,
  they are all affine and have the same size in the sense that for each $\Spec A_x\colonequiv \fib_s(x)$,
  we have that $A_x$ is free of rank 2 as an $R$-module.
  To see this, let us first note,
  that $\fib_s([x:y])$ is completely contained in an affine subset of $\bP^1$.
  This is a proposition, so we can use that either $x$ or $y$ is invertible.
  Let us assume without loss of generality, that $y$ is invertible,
  then
  \[
    \fib_s([x:y])=\fib_s([\frac{x}{y}:1])
    \rlap{.}
  \]
  The second component of each element in the fiber has to be invertible,
  so it is contained in an affine subset, which we identify with $\A^1$.
  Let us rewrite with $z\colonequiv \frac{x}{y}$.
  Then
  \[
    \fib_s([z:1])=\sum_{a:\A^1}(a^2=z)=\Spec R[X]/(X^2-z)
  \]
  and $R[X]/(X^2-z)$ is free of rank 2 as an $R$-module.
\end{example}

Let us now prove the special case $n = 1$ of our goal.

\begin{lemma}[using \axiomref{loc}, \axiomref{sqc}]%
  \label{functions-on-projective-line-constant}
  All functions $\bP^1 \to R$ are constant.
\end{lemma}

\begin{proof}
  Consider the affine cover of $\bP^1 = U_0 \cup U_1$
  as in the proof of \cref{projective-space-is-scheme}.
  Both $U_0$ and $U_1$ are isomorphic to $\A^1$
  and the intersection $U_0 \cap U_1$ is $\A^1 \setminus \{0\}$,
  embedded in $U_0$ by $x \mapsto x$
  and in $U_1$ by $x \mapsto \frac{1}{x}$.
  So we have a pushout square as follows.
  \[ \begin{tikzcd}
    \A^1 \setminus \{0\} \ar[r] \ar[d]
    \ar[dr, phantom, very near end, "\ulcorner"] &
    \A^1 \ar[d] \\
    \A^1 \ar[r] &
    \bP^1
  \end{tikzcd} \]
  If we apply the functor $X \mapsto R^X$ to this diagram,
  we obtain a pullback square of $R$ algebras,
  and we can insert the known $R$ algebras for the affine schemes involved.
  \[ \begin{tikzcd}
    R[X, Y]/(1 - XY) &
    R[Y] \ar[l] \\
    R[X] \ar[u] &
    R^{\bP^1} \ar[l] \ar[u]
    \ar[lu, phantom, very near start, "\ulcorner"]
  \end{tikzcd} \]
  Here, the different variable names $X$ and $Y$ indicate
  the resulting homomorphisms.
  Now it is an algebraic computation,
  understanding the elements of $R[X, Y]/(1 - XY)$ as Laurent polynomials,
  to see that the pullback is the algebra $R$,
  so we have $R^{\bP^1} = R$ as desired.
\end{proof}

\begin{lemma}[using \axiomref{sqc}, \axiomref{loc}]%
  \label{parametrized-line-through-two-points-in-projective-space}
  Let $p \neq q \in \bP^n$ be given.
  Then there exists a map $f : \bP^1 \to \bP^n$
  such that $f([0 : 1]) = p$, $f([1 : 0]) = q$.
\end{lemma}

\begin{proof}
  What we want to prove is a proposition,
  so we can assume chosen $a, b \in \A^{n+1} \setminus \{0\}$
  with $p = [a]$, $q = [b]$.
  Then we set
  \[ f([x, y]) \colonequiv [xa + yb] \rlap{.}\]
  Let us check that $xa + yb \neq 0$.
  By \cref{generalized-field-property},
  we have that $x$ or $y$ is invertible
  and both $a$ and $b$ have at least one invertible entry.
  If $xa = - yb$
  then it follows that $x$ and $y$ are both invertible
  and therefore $a$ and $b$ would be linearly equivalent,
  contradicting the assumption $p \neq q$.
  Of course $f$ is also well-defined
  with respect to linear equivalence in the pair $(x, y)$.
\end{proof}

\begin{lemma}[using \axiomref{loc}, \axiomref{sqc}]%
  \label{point-in-projective-space-apart-from-two-standard-points}
  Let $n \geq 1$.
  For every point $p \in \bP^n$,
  we have $p \neq [1 : 0 : 0 : \dots]$
  or $p \neq [0 : 1 : 0 : \dots]$.
\end{lemma}

\begin{proof}
  This is a special case of \cref{projective-space-apartness-relation},
  but we can also give a very direct proof:
  Let $p = [a]$ with $a \in \A^{n+1} \setminus \{0\}$.
  By \cref{generalized-field-property},
  there is an $i \in \{0, \dots, n\}$ with $a_i \neq 0$.
  If $i = 0$ then $p \neq [0 : 1 : 0 : \dots]$,
  if $i \geq 1$ then $p \neq [1 : 0 : 0 : \dots]$.
\end{proof}

\begin{theorem}[using \axiomref{loc}, \axiomref{sqc}]%
  \label{functions-on-projective-space-constant}
  All functions $\bP^n \to R$ are constant,
  that is,
  \[ H^0(\bP^n, R) \colonequiv (\bP^n \to R) = R \rlap{.} \]
\end{theorem}

\begin{proof}
  Let $f : \bP^n \to R$ be given.
  For any two distinct points $p \neq q : \bP^n$,
  we can apply \cref{parametrized-line-through-two-points-in-projective-space}
  and (merely) find a map $\widetilde{f} : \bP^1 \to R$
  with $\widetilde{f}([0 : 1]) = f(p)$
  and $\widetilde{f}([1 : 0]) = f(q)$.
  Then we see $f(p) = f(q)$
  by \cref{functions-on-projective-line-constant}.
  In particular, we have $f([1 : 0 : 0 : \dots]) = f([0 : 1 : 0 : \dots])$.
  And then, by \cref{point-in-projective-space-apart-from-two-standard-points},
  we get $f(p) = f([1 : 0 : 0 : \dots])$ for every $p : \bP^n$.
\end{proof}


\subsection{Line Bundles}

We will construct Serre's twisting sheaves in this section,
starting with the ``minus first''.
The following works because of \cref{lines-are-one-dimensional}.

We will also give some indication on which line bundles exist in general.

\begin{definition}%
  Let $X$ be a type.
  A \notion{line bundle} is a map $\mathcal L : X\to \Mod{R}$,
  such that
  \[ \prod_{x:X} \propTrunc{\mathcal L_x=_{\Mod{R}}R} \rlap{.}\]
  The \notion{trivial line bundle} on $X$ is the line bundle
  $X \to \Mod{R}, x \mapsto R$,
  and when we say that a line bundle $\mathcal{L}$ is trivial
  we mean that $\mathcal{L}$ is equal to the trivial line bundle,
  or equivalently $\propTrunc{\prod_{x:X} \mathcal L_x=_{\Mod{R}}R}$.
\end{definition}

\begin{definition}
  \begin{enumerate}[(a)]
  \item The \notion{tautological bundle} is the line bundle $\mathcal O_{\bP^n}(-1):\bP^n\to \Mod{R}$,
    given by
    \[ (L:\bP^n)\mapsto L\rlap{.}\]
  \item The \notion{dual}\index{$\mathcal L^\vee$} $\mathcal L^\vee$ of a line bundle $\mathcal L:\bP^n\to \Mod{R}$,
    is the line bundle given by
    \[ (x:\bP^n)\mapsto \Hom_{\Mod{R}}(\mathcal L_x,R)\rlap{.}\]
  \item The \notion{tensor product} of $R$-module bundles $\mathcal F\otimes \mathcal G$\index{$\mathcal F\otimes \mathcal G$}
    on a scheme $X$
    is given by pointwise taking the tensor product of $R$-modules.
  \item For $k:\Z$, the $k$-th \notion{Serre twisting sheaf} on $\bP^n$
    is given by taking the $-k$-th tensor power of $\mathcal O_{\bP^n}(-1)$ for negative $k$
    and the $k$-th tensor power of $\mathcal O_{\bP^n}(-1)^{\vee}$ otherwise.
  \end{enumerate}
\end{definition}

With this, we expect that many classical results can be reproduced.
It is however, far from clear, in what sense we can expect that every line bundle on $\bP^n$
is a Serre twisting sheaf.
The expectation is, that this is not the case,
since even on $\A^1$, we should not expect that all line bundles are trivial.
The background of this expectation is the external fact, that the relative picard group of
the affine line over the spectrum of the base ring is not always trivial.

We will proceed by showing the claim about line bundles on $\A^1$,
which will require some preparation.

\begin{lemma}[using \axiomref{loc}, \axiomref{sqc}, \axiomref{Z-choice}]
  For every open subset $U : \A^1 \to \Prop$ of $\A^1$
  we have not not:
  either $U = \emptyset$
  or $U = D((X - a_1)\dots(X - a_n)) = \A^1 \setminus \{ a_1, \dots, a_n \}$
  for pairwise distinct numbers $a_1, \dots, a_n : R$.
\end{lemma}

\begin{proof}
  For $U = D(f)$,
  this follows from \cref{polynomials-notnot-decompose}
  because $D(\alpha \cdot {(X - a_1)}^{e_1} \dots {(X - a_n)}^{e_n})
  = D((X - a_1) \dots (X - a_n))$.
  In general,
  we have $U = D(f_1) \cup \dots \cup D(f_n)$
  by \cref{qc-open-affine-open},
  so we do not not get
  (that $U = \emptyset$ or)
  a list of elements $a_1, \dots, a_n : R$
  such that $U = \A^1 \setminus \{ a_1, \dots, a_n \}$.
  Then we can not not get rid of any duplicates in the list.
\end{proof}

\begin{lemma}[using \axiomref{loc}, \axiomref{sqc}, \axiomref{Z-choice}]%
  \label{decompose-invertible-function-on-intersection-in-A1}
  Let $U, V : \A^1 \to \Prop$ be two open subsets
  and let $f : U \cap V \to R^\times$ be a function.
  Then there do not not exist functions
  $g : U \to R^\times$ and
  $h : V \to R^\times$
  such that $f(x) = g(x)h(x)$ for all $x : U \cap V$.
\end{lemma}

\begin{proof}
  By \cref{polynomials-notnot-decompose},
  we can assume
  \begin{align*}
    U \cup V &= D((X - a_1) \dots (X - a_k)) \rlap{,}\\
    U &= D((X - a_1) \dots (X - a_k) (X - b_1) \dots (X - b_l)) \rlap{,}\\
    V &= D((X - a_1) \dots (X - a_k) (X - c_1) \dots (X - c_m)) \rlap{,}\\
    U \cap V &= D((X - a_1) \dots (X - a_k) (X - b_1) \dots (X - b_l) (X - c_1) \dots (X - c_m))
    \rlap{,}
  \end{align*}
  where all linear factors are distinct.
  Then every function $f : U \cap V \to R^\times$ can
  by (\axiomref{sqc}), \cref{polynomials-notnot-decompose}
  and comparing linear factors
  not not be written in the form
  \[ f = \alpha \cdot
     {(X - a_1)}^{e_1} \dots {(X - a_k)}^{e_k}
     {(X - b_1)}^{e'_1} \dots {(X - b_l)}^{e'_l}
     {(X - c_1)}^{e''_1} \dots {(X - c_m)}^{e''_m}
  \]
  with $\alpha : R^\times$, $e_i, e'_i, e''_i : \Z$.
  Other linear factors can not appear,
  since they do not represent invertible functions on $U \cap V$.
  Now we can write $f = gh$ as desired,
  for example with
  \begin{align*}
    g &= \alpha \cdot
    {(X - a_1)}^{e_1} \dots {(X - a_k)}^{e_k}
    {(X - b_1)}^{e'_1} \dots {(X - b_l)}^{e'_l} \rlap{,}\\
    h &=
    {(X - c_1)}^{e''_1} \dots {(X - c_m)}^{e''_m} \rlap{.}
  \end{align*}
\end{proof}

\begin{theorem}[using \axiomref{loc}, \axiomref{sqc}, \axiomref{Z-choice}]%
  \label{Gm-torsors-on-A1}
  Every $R^\times$-torsor on $\A^1$ (\cref{torsor})
  does not not have a global section.
\end{theorem}

\begin{proof}
  Let $T$ be an $R^\times$-torsor on $\A^1$,
  that is,
  for every $x : \A^1$,
  $T_x$ is a set with a free and transitive $R^\times$ action
  and $\propTrunc{T_x}$.
  By (\axiomref{Z-choice}),
  we get a cover of $\A^1$ by open subsets $\A^1 = \bigcup_{i = 1}^n U_i$
  and local sections $s_i : (x : U_i) \to T_x$ of the bundle $T$.
  From this we can not not construct a global section by induction on $n$:
  Given any two local sections $s_i, s_j$ defined on $U_i, U_j$,
  let $f : U_i \cap U_j \to R^\times$ be the unique function with
  $f(x)s_i(x) = s_j(x)$ for all $x : U_i \cap U_j$.
  Then by \cref{decompose-invertible-function-on-intersection-in-A1},
  we not not find $g : U_i \to R^\times$, $h : U_j \to R^\times$
  such that the sections
  $x \mapsto g(x)s_i(x)$ and $x \mapsto {h(x)}^{-1}s_j(x)$,
  defined on $U_i$ respectively $U_j$,
  agree on $U_i \cap U_j$.
  This yields a section $\widetilde{s} : (x : U_i \cup U_j) \to T_x$
  by \cref{kraus-glueing}
  and we can replace $U$ and $V$ by $U \cup V$ in the cover.
  Finally, when we get to $n = 1$,
  we have $U_1 = \A^1$
  and the global section $s_1 : (x : X) \to T_x$.
\end{proof}

\begin{corollary}[using \axiomref{loc}, \axiomref{sqc}, \axiomref{Z-choice}]
  Every line bundle on $\A^1$ is not not trivial.
\end{corollary}

\begin{proof}
  Given a line bundle $L$,
  we can construct an $R^\times$ torsor
  \[ x \mapsto L_x \setminus \{0\} \rlap{.} \]
  Note that there is a well-defined $R^\times$ action on $M \setminus \{0\}$
  for every $R$ module $M$,
  and the action on $L_x \setminus \{0\}$ is free and transitive
  and we have $\propTrunc{L_x \setminus \{0\}}$
  since we merely have $L_x = R$ as $R$ modules.
  By \cref{Gm-torsors-on-A1},
  there not not is a global section of this torsor,
  so we have a section $s : (x : \A^1) \to L_x$
  with $s(x) \neq 0$ for all $x : \A^1$.
  But this means that the line bundle $L$ is trivial,
  since we can build an identification $L_x = R$
  by sending $s(x)$ to $1$.
\end{proof}
